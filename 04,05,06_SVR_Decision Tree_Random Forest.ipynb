{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:\\\\Kaustav MBA\\\\TERM3\\\\Machine_Learning\\\\Position_Salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Consultant</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager</td>\n",
       "      <td>4</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country Manager</td>\n",
       "      <td>5</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position  Level  Salary\n",
       "0   Business Analyst      1   45000\n",
       "1  Junior Consultant      2   50000\n",
       "2  Senior Consultant      3   60000\n",
       "3            Manager      4   80000\n",
       "4    Country Manager      5  110000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[ : , 1:2].values\n",
    "Y=data.iloc[ : ,2:].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.transform(x_test)\n",
    "X=sc_x.transform(X)\n",
    "sc_y=StandardScaler()\n",
    "y_train=sc_y.fit_transform(y_train)\n",
    "y_test=sc_y.transform(y_test)\n",
    "Y=sc_y.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Payal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor=SVR(kernel='rbf')\n",
    "regressor.fit(X,Y)\n",
    "plt.scatter(X,Y,color=\"red\")\n",
    "plt.plot(X,regressor.predict(X),color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171640.87069654]\n"
     ]
    }
   ],
   "source": [
    "print(sc_y.inverse_transform(regressor.predict(sc_x.transform([[6.5]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24101628]\n"
     ]
    }
   ],
   "source": [
    "print(regressor.predict(sc_x.transform([[6.5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVR in module sklearn.svm._classes:\n",
      "\n",
      "class SVR(sklearn.base.RegressorMixin, sklearn.svm._base.BaseLibSVM)\n",
      " |  SVR(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |  \n",
      " |  Epsilon-Support Vector Regression.\n",
      " |  \n",
      " |  The free parameters in the model are C and epsilon.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time complexity\n",
      " |  is more than quadratic with the number of samples which makes it hard\n",
      " |  to scale to datasets with more than a couple of 10000 samples. For large\n",
      " |  datasets consider using :class:`sklearn.svm.LinearSVR` or\n",
      " |  :class:`sklearn.linear_model.SGDRegressor` instead, possibly after a\n",
      " |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  kernel : string, optional (default='rbf')\n",
      " |       Specifies the kernel type to be used in the algorithm.\n",
      " |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |       a callable.\n",
      " |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |       used to precompute the kernel matrix.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, optional (default='scale')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  C : float, optional (default=1.0)\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive.\n",
      " |      The penalty is a squared l2 penalty.\n",
      " |  \n",
      " |  epsilon : float, optional (default=0.1)\n",
      " |       Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
      " |       within which no penalty is associated in the training loss function\n",
      " |       with points predicted within a distance epsilon from the actual\n",
      " |       value.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |  \n",
      " |  coef_ : array, shape = [1, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : array, shape = [1]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import SVR\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> rng = np.random.RandomState(0)\n",
      " |  >>> y = rng.randn(n_samples)\n",
      " |  >>> X = rng.randn(n_samples, n_features)\n",
      " |  >>> clf = SVR(C=1.0, epsilon=0.2)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  SVR(epsilon=0.2)\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  NuSVR\n",
      " |      Support Vector Machine for regression implemented using libsvm\n",
      " |      using a parameter to control the number of support vectors.\n",
      " |  \n",
      " |  LinearSVR\n",
      " |      Scalable Linear Support Vector Machine for regression\n",
      " |      implemented using liblinear.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  **References:**\n",
      " |  `LIBSVM: A Library for Support Vector Machines\n",
      " |  <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`__\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVR\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with :func:`~sklearn.metrics.r2_score`. This will influence the\n",
      " |      ``score`` method of all the multioutput regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`). To specify the\n",
      " |      default value manually and avoid the warning, please either call\n",
      " |      :func:`~sklearn.metrics.r2_score` directly or make a custom scorer with\n",
      " |      :func:`~sklearn.metrics.make_scorer` (the built-in scorer ``'r2'`` uses\n",
      " |      ``multioutput='uniform_average'``).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform regression on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 (inlier) or -1 (outlier) is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -- Feature Scaling is not required in decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DecisionTreeRegressor in module sklearn.tree._classes:\n",
      "\n",
      "class DecisionTreeRegressor(sklearn.base.RegressorMixin, BaseDecisionTree)\n",
      " |  DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, presort='deprecated', ccp_alpha=0.0)\n",
      " |  \n",
      " |  A decision tree regressor.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : {\"mse\", \"friedman_mse\", \"mae\"}, default=\"mse\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"mse\" for the mean squared error, which is equal to variance\n",
      " |      reduction as feature selection criterion and minimizes the L2 loss\n",
      " |      using the mean of each terminal node, \"friedman_mse\", which uses mean\n",
      " |      squared error with Friedman's improvement score for potential splits,\n",
      " |      and \"mae\" for the mean absolute error, which minimizes the L1 loss\n",
      " |      using the median of each terminal node.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |  splitter : {\"best\", \"random\"}, default=\"best\"\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int or RandomState, default=None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  presort : deprecated, default='deprecated'\n",
      " |      This parameter is deprecated and will be removed in v0.24.\n",
      " |  \n",
      " |      .. deprecated:: 0.22\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the\n",
      " |      (normalized) total reduction of the criterion brought\n",
      " |      by that feature. It is also known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier : A decision tree classifier.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_boston\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeRegressor\n",
      " |  >>> X, y = load_boston(return_X_y=True)\n",
      " |  >>> regressor = DecisionTreeRegressor(random_state=0)\n",
      " |  >>> cross_val_score(regressor, X, y, cv=10)\n",
      " |  ...                    # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 0.61..., 0.57..., -0.34..., 0.41..., 0.75...,\n",
      " |          0.07..., 0.29..., 0.33..., -1.42..., -1.77...])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseDecisionTree\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='mse', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, presort='deprecated', ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree regressor from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (real numbers). Use ``dtype=np.float64`` and\n",
      " |          ``order='C'`` for maximum efficiency.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like of shape (n_samples, n_features),             default=None\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : DecisionTreeRegressor\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_classes_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with :func:`~sklearn.metrics.r2_score`. This will influence the\n",
      " |      ``score`` method of all the multioutput regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`). To specify the\n",
      " |      default value manually and avoid the warning, please either call\n",
      " |      :func:`~sklearn.metrics.r2_score` directly or make a custom scorer with\n",
      " |      :func:`~sklearn.metrics.make_scorer` (the built-in scorer ``'r2'`` uses\n",
      " |      ``multioutput='uniform_average'``).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Return the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples,)\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  cost_complexity_pruning_path(self, X, y, sample_weight=None)\n",
      " |      Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
      " |      \n",
      " |      See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
      " |      process.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ccp_path : Bunch\n",
      " |          Dictionary-like object, with attributes:\n",
      " |      \n",
      " |          ccp_alphas : ndarray\n",
      " |              Effective alphas of subtree during pruning.\n",
      " |      \n",
      " |          impurities : ndarray\n",
      " |              Sum of the impurities of the subtree leaves for the\n",
      " |              corresponding alpha value in ``ccp_alphas``.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator CSR matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  get_depth(self)\n",
      " |      Return the depth of the decision tree.\n",
      " |      \n",
      " |      The depth of a tree is the maximum distance between the root\n",
      " |      and any leaf.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.max_depth : int\n",
      " |          The maximum depth of the tree.\n",
      " |  \n",
      " |  get_n_leaves(self)\n",
      " |      Return the number of leaves of the decision tree.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.n_leaves : int\n",
      " |          Number of leaves.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          Normalized total reduction of criteria by feature\n",
      " |          (Gini importance).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:\\\\Kaustav MBA\\\\TERM3\\\\Machine_Learning\\\\Position_Salaries.csv\")\n",
    "reg = DecisionTreeRegressor()\n",
    "X=data.iloc[ : , 1:2].values\n",
    "Y=data.iloc[ : ,2:].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=reg.predict([[9.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([500000.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = np.arange(min(X),max(X),0.01)\n",
    "x_grid=x_grid.reshape(len(x_grid),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X,Y)\n",
    "plt.plot(x_grid,reg.predict(x_grid))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:\\\\Kaustav MBA\\\\TERM3\\\\Machine_Learning\\\\Position_Salaries.csv\")\n",
    "reg_rf = RandomForestRegressor(n_estimators=5,max_depth=2)#No. of bags/trees\n",
    "X=data.iloc[ : , 1:2].values\n",
    "Y=data.iloc[ : ,2:].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Payal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=5, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_rf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X,Y)\n",
    "plt.plot(x_grid,reg.predict(x_grid))\n",
    "plt.plot(x_grid,reg_rf.predict(x_grid),color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
